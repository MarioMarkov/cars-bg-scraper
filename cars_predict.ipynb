{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarioMarkov/cars-predict/blob/master/cars_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wf7OXBrfoI-4",
        "outputId": "93a65923-fe6c-456c-91d2-80382f802bcc"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m preprocessing\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_absolute_error\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from xgboost import XGBRegressor\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from pandas.plotting import scatter_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        " \n",
        "\n",
        "\n",
        "#Load data\n",
        "data = pd.read_csv('/content/cars-data3.csv', index_col=None)\n",
        "test = pd.read_csv('/content/test-data.csv',  index_col=None)\n",
        "\n",
        "#data.price = np.log10(data.price) \n",
        "#data.drop(['fuel'],axis='columns')\n",
        "#test.drop(['fuel'],axis='columns')\n",
        "\n",
        "# Remove Id column\n",
        "data = data.drop(['id'],axis='columns')\n",
        "#data = data.drop(['displacement'],axis='columns')\n",
        "#test = test.drop(['displacement'],axis='columns')\n",
        "\n",
        "#test = test.drop(['price'],axis='columns')\n",
        "\n",
        "\n",
        "# Remove brands that are seen less than 200 times\n",
        "data = data.groupby('brand').filter(lambda x :len(x)>200)\n",
        "\n",
        "corr_matrix = data.corr()\n",
        "print(corr_matrix[\"price\"].sort_values(ascending=False))\n",
        "\n",
        "#Format BMW model\n",
        "def format_bmw_model(model_name):\n",
        "  if 'X' in model_name or 'i' in model_name:\n",
        "    return model_name\n",
        "  return model_name[0]\n",
        "\n",
        "# Trim model to just 1 letter except if it is X or i ex.(318 to 3)\n",
        "print(data.loc[data['brand'] == 'Hyundai', ['model']].value_counts())\n",
        "data.loc[data['brand'] == 'BMW', ['model']] = data[data.brand == 'BMW'].model.apply(lambda x: format_bmw_model(x))\n",
        "\n",
        "# Remove models that are met less than 9 times\n",
        "data = data.groupby('model').filter(lambda x :len(x)>9)\n",
        "\n",
        "# Impute columns records with missing values with median or mode\n",
        "data.kms.fillna(data.kms.median(), inplace = True)\n",
        "# print(data[\"displacement\"].unique())\n",
        "# data[\"displacement\"] = data[\"displacement\"].str.strip(\" \")\n",
        "# data[\"displacement\"] = data[\"displacement\"].str.strip(\",\")\n",
        "# print(data[\"displacement\"].unique())\n",
        "# print(data.dtypes)\n",
        "# data[\"displacement\"] = pd.to_numeric(data[\"displacement\"])\n",
        "#print(data.dtypes)\n",
        "\n",
        "# TODO maybe not right \n",
        "data = data.fillna(data.mode().iloc[0])\n",
        "\n",
        "\n",
        "# Print columns that have missing values \n",
        "# print(data.apply(lambda x: sum(x.isnull()),axis=0) )\n",
        "\n",
        "print(data.price.describe())\n",
        "# Remove outliers in IQR \n",
        "Q3 = np.quantile(data.price, 0.95)\n",
        "Q1 = np.quantile(data.price, 0.10)\n",
        "IQR = Q3 - Q1\n",
        "lower_range = Q1 - 1.5 * IQR\n",
        "upper_range = Q3 + 1.5 * IQR\n",
        "outlier_free_list = [x for x in data.price if (\n",
        "    (x > lower_range) & (x < upper_range))]\n",
        "data = data.loc[data.price.isin(outlier_free_list)]\n",
        "\n",
        "Q3 = np.quantile(data.kms, 0.95)\n",
        "Q1 = np.quantile(data.kms, 0.40)\n",
        "IQR = Q3 - Q1\n",
        "lower_range = Q1 - 1.5 * IQR\n",
        "upper_range = Q3 + 1.5 * IQR\n",
        "outlier_free_list = [x for x in data.kms if (\n",
        "    (x > lower_range) & (x < upper_range))]\n",
        "data = data.loc[data.kms.isin(outlier_free_list)]\n",
        "\n",
        "print(data.price.describe())\n",
        "data.price = np.log(data.price)\n",
        "# Encoding string columns to numeric\n",
        "\n",
        "ordinal_enc_cols = ['brand','model','color','type']\n",
        "one_hot_columns = ['fuel']\n",
        "\n",
        "ordinal_encoder = OrdinalEncoder()\n",
        "data[ordinal_enc_cols] = ordinal_encoder.fit_transform(data[ordinal_enc_cols])\n",
        "test[ordinal_enc_cols] = ordinal_encoder.transform(test[ordinal_enc_cols])\n",
        "\n",
        "#scatter_matrix(data[['price','kms','year']], figsize=(12, 8))\n",
        "#sns.catplot(data=data, x=\"fuel\", y=\"price\",kind=\"box\")\n",
        "\n",
        "# Apply one-hot encoder to fuel column\n",
        "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "oh_columns_data = pd.DataFrame(OH_encoder.fit_transform(data[one_hot_columns]))\n",
        "oh_columns_test = pd.DataFrame(OH_encoder.transform(test[one_hot_columns])) \n",
        "\n",
        "# One-hot encoding removed index; put it back\n",
        "oh_columns_data.index = data.index\n",
        "oh_columns_test.index = test.index\n",
        "\n",
        "# Remove categorical columns (will replace with one-hot encoding)\n",
        "num_X_data = data.drop(one_hot_columns, axis=1)\n",
        "num_X_test = test.drop(one_hot_columns, axis=1)\n",
        "\n",
        "# Add one-hot encoded columns to numerical features\n",
        "data = pd.concat([num_X_data, oh_columns_data], axis=1)\n",
        "test = pd.concat([num_X_test, oh_columns_test], axis=1)\n",
        "\n",
        "# Standardize kms and year variables\n",
        "scaler = StandardScaler()\n",
        "# data[['kms', 'year']] = scaler.fit_transform(data[['kms', 'year']])\n",
        "# test[['kms', 'year']] = scaler.transform(test[['kms', 'year']])\n",
        "\n",
        "\n",
        "# Train set without price col\n",
        "X = data.drop(['price'],axis='columns')\n",
        "\n",
        "# Train set price col\n",
        "y = data.price\n",
        "\n",
        "\n",
        "# Getting mutual inforamtion scores\n",
        "for colname in X.select_dtypes(\"object\"):\n",
        "    X[colname], _ = X[colname].factorize()\n",
        "for colname in X.select_dtypes(\"float\"):\n",
        "    X[colname], _ = X[colname].factorize()\n",
        "y = y.round(0).astype(int)\n",
        "# discrete_features = X.dtypes == int\n",
        "\n",
        "# mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
        "\n",
        "# Space of possible hyperparameters\n",
        "\n",
        "\n",
        "\n",
        "# params = {'learning_rate': [0.05,0.07], #so called `eta` value\n",
        "#               'max_depth': [2,3,4],\n",
        "#               'n_estimators': [80,100],\n",
        "#               'colsample_bytree': [.2,.3,.4] }\n",
        "#{'colsample_bytree': 0.6, 'learning_rate': 0.07, 'max_depth': 5, 'nthread': 4}\n",
        "#{'colsample_bytree': 0.6, 'learning_rate': 0.07, 'max_depth': 5, 'n_estimators': 100}\n",
        "#{'colsample_bytree': 0.4, 'learning_rate': 0.07, 'max_depth': 2, 'n_estimators': 100}\n",
        "# Defining model to try hyperparameters from space on\n",
        "# Lowering n_estimators improoves prediction on new data,\n",
        "# but lowers score for test data\n",
        "xgb_model = XGBRegressor(random_state=1,objective='reg:squarederror',\n",
        "                         learning_rate = 0.08,\n",
        "                         max_depth = 3,\n",
        "                         colsample_bytree =0.4,\n",
        "                         n_estimators = 100)\n",
        "\n",
        "#model = GridSearchCV(xgb_model, param_grid=params, cv=3, verbose=1,n_jobs=1, \n",
        "#                     return_train_score=True)\n",
        "\n",
        "\n",
        "# Fit model\n",
        "xgb_model.fit(X,y)\n",
        "\n",
        "#Calculate error \n",
        "mae = -1 * cross_val_score(xgb_model, X, y,\n",
        "                                  cv=3,\n",
        "                                  scoring='neg_mean_absolute_error')\n",
        "\n",
        "\n",
        "#Supress scientific notation\n",
        "pd.options.display.float_format = '{:.10f}'.format\n",
        "\n",
        "\n",
        "print(mae.mean())\n",
        "\n",
        "submission_predictions =  xgb_model.predict(test)\n",
        "submission_predictions = submission_predictions\n",
        "submission_predictions = np.exp(submission_predictions)\n",
        "print(submission_predictions)\n",
        "#data.hist(bins=50, figsize=(20,15))\n",
        "#print(model.best_params_)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMvF+UyHAvyIOPobgu+eVQr",
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "eabeb96e05935367cdf0ccbdcdda22fabfeef502457390132bd920104f92b1c8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
